{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054274ff-50e7-489d-aecb-99adedd9b58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import LCMScheduler, AutoPipelineForText2Image\n",
    "\n",
    "# https://huggingface.co/latent-consistency/lcm-lora-sdv1-5\n",
    "model_id = \"Lykon/dreamshaper-8\"\n",
    "adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.to(\"mps\")\n",
    "\n",
    "# nope, not for mps\n",
    "# pipe = torch.compile(pipe)\n",
    "\n",
    "# load and fuse lcm lora\n",
    "pipe.load_lora_weights(adapter_id)\n",
    "pipe.fuse_lora()\n",
    "\n",
    "# 512x512 image\n",
    "prompt = \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # disable guidance_scale by passing 0\n",
    "    image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "742a46b7-074a-4a5b-8db8-741895d75192",
   "metadata": {},
   "source": [
    "from diffusers import AutoPipelineForText2Image, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained('lykon/dreamshaper-xl-v2-turbo', torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"mps\")\n",
    "\n",
    "# prompt = \"portrait photo of muscular bearded guy in a worn mech suit, light bokeh, intricate, steel metal, elegant, sharp focus, soft lighting, vibrant colors\"\n",
    "prompt = \"high quality picture, award winning landscape photography of Tokyo, Japan, 4k\"\n",
    "\n",
    "generator = torch.manual_seed(0)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_xl = pipe(prompt, num_inference_steps=6, guidance_scale=2).images[0]  \n",
    "    # image.save(\"./image.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "52a01753-fd9f-4859-90d9-31919f86740e",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"high quality picture, award winning landscape photography of Tokyo, Japan, detailed, 8k\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_xl = pipe(\n",
    "        prompt, num_inference_steps=6, guidance_scale=2,\n",
    "        # width=1024, height=1024, # 60s\n",
    "        width=256, height=256, # 4s\n",
    "    ).images[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d403dc-14c0-41b6-b74a-2a8f22f24cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# mps: 3.0s\n",
    "\n",
    "# prompt = \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
    "# prompt = \"high quality picture, award winning landscape photography of Tokyo, Japan, 4k\"\n",
    "# prompt = \"award winning photography of Tokyo, Japan, detailed, 8k, daytime\"\n",
    "# prompt = \"high quality picture, award winning photography of Tokyo, Japan, detailed, 8k, daytime, aesthetic, magazine cover, 8k\"\n",
    "# prompt = \"photography of Tokyo, Japan\"\n",
    "prompt = \"photography of Jersey Island, United Kingdom\"\n",
    "negative_prompt = None\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # disable guidance_scale by passing 0\n",
    "    # image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=6,\n",
    "        # guidance_scale should be 0, or in 1-2\n",
    "        guidance_scale=2,\n",
    "        width=512, height=512, # 3s\n",
    "        # width=256, height=256, # 0.9s\n",
    "    ).images[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd6e2c-b383-4a2b-b05d-2e532b97390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f7bfa-200c-430b-8e51-3ef75f62eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# Work fast, low diversity\n",
    "# https://github.com/IDKiro/sdxs\n",
    "# https://huggingface.co/IDKiro/sdxs-512-0.9\n",
    "# seed = 42\n",
    "# weight_type = torch.float32\n",
    "weight_type = torch.float16\n",
    "\n",
    "# https://github.com/IDKiro/sdxs\n",
    "# Load model.\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    # \"IDKiro/sdxs-512-0.9\",\n",
    "    \"IDKiro/sdxs-512-dreamshaper\",\n",
    "    torch_dtype=weight_type,\n",
    ")\n",
    "\n",
    "# use original VAE\n",
    "# pipe.vae = AutoencoderKL.from_pretrained(\"IDKiro/sdxs-512-0.9/vae_large\")\n",
    "pipe.to(\"mps\")\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "# 512x512 image\n",
    "prompt = \"high quality picture, award winning photography of Saint Pierre and Miquelon, France, detailed, daytime, aesthetic, magazine cover, 8k\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image = pipe(\n",
    "        prompt=prompt, num_inference_steps=1, guidance_scale=0\n",
    "    ).images[0]\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c51b67f3-9eab-4671-b015-cf47179d3bf8",
   "metadata": {},
   "source": [
    "import unicodedata\n",
    "def strip_accents(s):\n",
    "    # return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    return unicodedata.normalize('NFKD', s).encode('ASCII', 'ignore').decode()\n",
    "\n",
    "strip_accents(\"adélie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf576cf-86d6-41ba-a870-4128744722f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "place = \"Jersey Island, United Kingdom\"\n",
    "place = \"Tokyo, Japan\"\n",
    "place = \"Kerguelen Islands, France\"\n",
    "place = \"Terrer Adélie, Antarctica\"\n",
    "place = \"Clipperton Island, France\"\n",
    "place = \"Saint Pierre and Miquelon, France\"\n",
    "place = \"Saint Barthélemy, France\"\n",
    "place = \"Rome, Italy\"\n",
    "\n",
    "prompt = f\"high quality picture, award winning photography of {place}, detailed, daytime, aesthetic, 8k\"\n",
    "# prompt = f\"award winning photography of {place}\"\n",
    "\n",
    "# with torch.inference_mode(mode=True):\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    # negative_prompt=negative_prompt,  # no effect\n",
    "    num_inference_steps=1,\n",
    "    guidance_scale=0,\n",
    "    # guidance_scale=1,\n",
    "    width=512, height=512, # 0.3s\n",
    "    # width=256, height=256, # 0.17s ~100ms\n",
    "    # clip_skip=3,\n",
    "    generator=g,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b9eed-fd6a-4406-bcb0-002b258d8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc830c1d-fd9e-4be8-8535-943d0d1f1cd2",
   "metadata": {},
   "source": [
    "Try CoreML based stuff:\n",
    "\n",
    "SDXS model already converted:\n",
    "https://huggingface.co/lsb/6-bit-palettized-sdxs-512-dreamshaper/tree/main\n",
    "\n",
    "Look at examples here:\n",
    "https://huggingface.co/apple/coreml-stable-diffusion-2-1-base-palettized\n",
    "\n",
    "Inference like that:\n",
    "https://github.com/apple/ml-stable-diffusion/blob/main/python_coreml_stable_diffusion/pipeline.py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3478d595-4e7e-49ad-ac60-67e16758aea5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from diffusers import PixArtAlphaPipeline\n",
    "import torch\n",
    "\n",
    "torch_dtype = torch.float16\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# https://huggingface.co/PixArt-alpha/PixArt-XL-2-256x256\n",
    "# https://huggingface.co/PixArt-alpha/PixArt-XL-2-256x256/blob/main/transformer/diffusion_pytorch_model.safetensors\n",
    "# pipe = PixArtAlphaPipeline.from_pretrained(\"PixArt-alpha/PixArt-XL-2-1024-MS\", torch_dtype=torch.float16)\n",
    "pipe = PixArtAlphaPipeline.from_pretrained(\"raman07/pixart-alpha-256x256\", torch_dtype=torch.float16)\n",
    "\n",
    "pipe.to(device=device, dtype=torch_dtype)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e0eadc2-9021-42b9-a8d4-4aa5e2611d97",
   "metadata": {},
   "source": [
    "prompt = \"award winning photography of Tokyo, Japan, detailed, 8k, daytime, cheerful\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # disable guidance_scale by passing 0\n",
    "    # image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0).images[0]\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        # guidance_scale should be 0, or in 1-2\n",
    "        # num_inference_steps=4, guidance_scale=0,\n",
    "        # num_inference_steps=4, guidance_scale=1,\n",
    "        # num_inference_steps=4, guidance_scale=2,\n",
    "        num_inference_steps=6, guidance_scale=0,  # 4s\n",
    "        width=512, height=512, # 3s\n",
    "        # width=256, height=256, # 0.9s\n",
    "    ).images[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e59a7da8-1f7d-4fd9-a593-9c1fd7caaefe",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import DiffusionPipeline, AutoencoderTiny\n",
    "\n",
    "# from diffusers import LCMScheduler, AutoPipelineForText2Image\n",
    "\n",
    "base_model = \"SimianLuo/LCM_Dreamshaper_v7\"\n",
    "taesd_model = \"madebyollin/taesd\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e77ac4a6-71c8-417b-8c1d-7c48b99d90cf",
   "metadata": {},
   "source": [
    "torch_dtype = torch.float16\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "pipe.to(device=device, dtype=torch_dtype)\n",
    "\n",
    "results = self.pipe(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    prompt=prompt,\n",
    "    generator=generator,\n",
    "    num_inference_steps=params.steps,\n",
    "    guidance_scale=params.guidance_scale,\n",
    "    width=params.width,\n",
    "    height=params.height,\n",
    "    output_type=\"pil\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
